{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "0f279b2f-1a02-4cdb-bf96-6d0d26734877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improting of libaries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bc11937f-47a5-4d6e-af61-821d243f2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_dataset(filepath):\n",
    "    print('=' * 60)\n",
    "    print(\"LOAD AND EXPLORE DATASET\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    print('shape of the dataset:')\n",
    "    print(df.shape)\n",
    "    print('\\nCheck for missing values:')\n",
    "    print(df.isnull().sum())\n",
    "    print('\\nFirst five rows:')\n",
    "    print(df.head())\n",
    "    print('\\nDescriptive Stats:')\n",
    "    print(df.describe())\n",
    "    print('\\nDataset info:')\n",
    "    print(df.info())\n",
    "    print('\\Exited Distribution:')\n",
    "    print(df['Exited'].value_counts())\n",
    "    print('\\Exited Percentage Distribution:')\n",
    "    print(df['Exited'].value_counts(normalize=True)* 100)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "731c6373-978a-43a0-8a07-5191847f3366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features(df):\n",
    "    print('=' * 60)\n",
    "    print(\"IDETIFYING  OF FEATURES \")\n",
    "    print('=' * 60)\n",
    "    # features to be drop(not useful)\n",
    "    features_to_drop = [\n",
    "        \"CustomerId\",\"Surname\"\n",
    "    ]\n",
    "\n",
    "    numerical_features = [\n",
    "        \"CreditScore\", \"Age\", \"Tenure\", 'EstimatedSalary',\n",
    "        'Balance', \"NumOfProducts\", \"ServiceRating\"\n",
    "    ]\n",
    "\n",
    "    categorical_features = [\n",
    "        \"Geography\", \"Gender\", \"HasCrCard\"\n",
    "    ] \n",
    "    print('\\nFeatueres to drop', features_to_drop)\n",
    "    print('\\nNumerical Features', numerical_features)\n",
    "    print('\\nCategorical Features', categorical_features)\n",
    "    return numerical_features, categorical_features, features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "07e9321e-c548-47e7-8273-7f5db4ea9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, numerical_features, categorical_features, features_to_drop):\n",
    "    print('=' * 60)\n",
    "    print(\"PREPARE  DATASET \")\n",
    "    print('=' * 60)\n",
    "\n",
    "    # drop unnecessary cols\n",
    "    df_model = df.drop(columns=features_to_drop)\n",
    "\n",
    "    # featyre to use\n",
    "    X = df_model.drop('Exited', axis= 1)\n",
    "    y = df_model['Exited']\n",
    "\n",
    "    print(\"\\nFeatures Shape\", X.shape)\n",
    "    print(\"\\nTarget Shape\", y.shape)\n",
    "    print(\"\\nFeature columns list\", list(X.columns))\n",
    "\n",
    "    return X, y, list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "c3a3443a-395b-40dc-a7ed-7bd921874379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline(numerical_features, categorical_features):\n",
    "    print('=' * 60)\n",
    "    print(\"CREATING PREPROCESSING  PIPELINE \")\n",
    "    print('=' * 60)\n",
    "\n",
    "    # nmerical_features pipeline\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # categorical features pipeline\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown = 'ignore'))\n",
    "    ])\n",
    "    #  column preprocessing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "8937d091-a1a4-4a7a-988f-d0fc6a4320c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    print('=' * 60)\n",
    "    print(\"SPLITTING DATA INTO TRAIN/TEST\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,y, test_size= test_size, random_state = random_state, stratify=y\n",
    "    )\n",
    "    print('\\nTrain set size', X_train.shape[0])\n",
    "    print('\\nTest set size', X_test.shape[0])\n",
    "    print('\\nTrain churn Distribution', y_train.value_counts())\n",
    "    print('\\nTest Churn Distribution', y_test.value_counts())\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "40f76069-b33b-442d-9653-a414b29062c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pipeline(preprocessor):\n",
    "    print('=' * 60)\n",
    "    print(\"CREATING MODEL PIPELINE\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(\n",
    "            max_iter =1000,\n",
    "            random_state = 42,\n",
    "            class_weight= 'balanced',\n",
    "            solver= 'lbfgs'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print('\\nModel pipeline created succesfully')\n",
    "\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "717320ac-46da-4fb2-a5b6-da55b56b131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_pipeline, X_train, y_train):\n",
    "    print('=' * 60)\n",
    "    print(\"TRAIN MODEL\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    print('\\nModel trained successfully')\n",
    "\n",
    "    # get name steps from preprocessing\n",
    "    try:\n",
    "        num_features = model_pipeline.named_steps['preprocessor'].transformers_[0][2]\n",
    "        cat_features = model_pipeline.named_steps['preprocessor'].transformers_[1][2]\n",
    "\n",
    "        # get name_Steps from onehotencoder\n",
    "        onehot_encoder = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_features_name = onehot_encoder.get_feature_names_out(cat_features)\n",
    "\n",
    "        all_features_name = list(num_features) + list(cat_features_name)\n",
    "\n",
    "        # get coefficient \n",
    "        coefficient = model_pipeline.named_steps['classifier'].coef_[0]\n",
    "        print('\\nTop 10 most importance fatures(by coefficent magnitude)')\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature_columns': all_features_name,\n",
    "            'coefficient': coefficient\n",
    "        }).sort_values('coefficient', key=abs, ascending=False)\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Can not extract features name {e}\")\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8a98d2d1-144f-4b1a-a823-d435c1526605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_pipeline, X_train, X_test, y_train, y_test):\n",
    "    print('=' * 60)\n",
    "    print(\"EVALUATING MODEL\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    y_train_pred = model_pipeline.predict(X_train)\n",
    "    y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "    # predict model prob\n",
    "    y_train_proba = model_pipeline.predict_proba(X_train)[:,1]\n",
    "    y_test_proba = model_pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # metrics \n",
    "    y_train_acc_score = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_acc_Score = accuracy_score(y_test_pred, y_test)\n",
    "\n",
    "    y_train_roc_score = roc_auc_score(y_train, y_train_proba)\n",
    "    y_test_roc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "    print(\"\\nMETRICS EVALUATION\")\n",
    "    print(f\"\\nTrain accuracy score:, {float(y_train_acc_score):.4f}\")\n",
    "    print(f\"\\nTest accuracy score:, {float(y_test_acc_Score):.4f}\")\n",
    "    print(f\"\\nTrain ROC Score:, {float(y_train_roc_score):.4f}\")\n",
    "    print(f\"\\nTest ROC Score:, {float(y_test_roc_score):.4f}\")\n",
    "\n",
    "    print(\"\\n CLASSIFICATION OF TRAIN SIZE\")\n",
    "    print(\"\\n Classification report\\n\", classification_report(y_train, y_train_pred, target_names = ['Retained','Churned']))\n",
    "    print(\"\\n CLASSIFICATION OF TEST SIZE\")\n",
    "    print(\"\\n Classification report\\n\", classification_report(y_test, y_test_pred, target_names = ['Retained','Churned']))\n",
    "\n",
    "    # cross validation score\n",
    "    cv_score = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    print('\\nCross Validation (5-folds)')\n",
    "    print(f'R2 Score:{cv_score}')\n",
    "    print(f'Cross Validation mean: {cv_score.mean():.2f}')\n",
    "    print(f\"Cross Validation STD : {cv_score.std():.4f}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"y_train_acc_score\": y_train_acc_score,\n",
    "        \"y_test_acc_Score\": y_test_acc_Score,\n",
    "        \"y_train_roc_score\": y_train_roc_score,\n",
    "        \"y_test_roc_score\": y_test_roc_score, \n",
    "        \"y_train_pred\": y_train_pred,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        'y_train_proba':y_train_proba,\n",
    "        \"y_test_proba\": y_test_proba,\n",
    "        \"cv_score\":cv_score,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "7d75de77-013f-4f0c-a9fa-890265a32470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_artifact(model_pipeline, feature_columns):\n",
    "    print('=' * 60)\n",
    "    print(\"SAVING MODEL ARTIFACT\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    joblib.dump(model_pipeline, 'churned_model_pipeline.pkl')\n",
    "    print('churned model pipeline saved successfully')\n",
    "    \n",
    "    joblib.dump(feature_columns, 'feature_columns.pkl')\n",
    "    print('feature columns saved successfully')\n",
    "\n",
    "    print('=' * 60)\n",
    "    print(\" MODEL ARTIFACT SAVED SUCCESSFULLY\")\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "f1834eeb-2390-4c4e-b691-8388a01224ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_churn (customer_data):\n",
    "    model_pipeline = joblib.load(\"churned_model_pipeline.pkl\")\n",
    "    feature_columns = joblib.load(\"feature_columns.pkl\")\n",
    "    customer_df = pd.DataFrame([customer_data])\n",
    "    for feature in feature_columns:\n",
    "        if feature not in customer_df.columns:\n",
    "            raise ValueError(f\"Missing require feature{feature}\")\n",
    "    customer_df = customer_df[feature_columns]\n",
    "    \n",
    "    prediction = model_pipeline.predict(customer_df)[0]\n",
    "    probability = model_pipeline.predict_proba(customer_df)[0]\n",
    "\n",
    "    result = {\n",
    "    'prediction': 'Churned' if prediction == 1 else \"Retained\",\n",
    "    'churn_probability': probability[0],\n",
    "    'retained_probability': probability[1],\n",
    "    'risk_level': 'High' if probability [1] > 0.7 else 'Medium' if probability[0] > 0.4 else 'Low'\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "de3df155-d372-4e8f-a5ba-d6d58d4e1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    customer_data = {\n",
    "\n",
    "        'CreditScore' :650,\n",
    "        'Geography': 'France',\n",
    "        'Gender' :'Male',\n",
    "        'Age' : 35,\n",
    "        'Tenure': 5,\n",
    "        'Balance': 10000.0,\n",
    "        'NumOfProducts': 2,\n",
    "        'HasCrCard': 'Yes',\n",
    "       'IsActiveMember' : 'Yes',\n",
    "        'EstimatedSalary': 80000.0,\n",
    "        'ServiceRating': 4\n",
    "    }\n",
    "\n",
    "    result = predict_churn (customer_data)\n",
    "    print(\"Prediction\", result['prediction'])\n",
    "    print(\"Churned Probability\", result['churn_probability'])\n",
    "    print(\"Retained Probability\", result['retained_probability'])\n",
    "    print(\"Risk Level\", result['risk_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "3bf8bfba-90d3-4145-b97e-765c32a0a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    filepath  = 'cleaned_bank_churned_dataset.csv'\n",
    "    df = load_and_explore_dataset(filepath)\n",
    "    numerical_features, categorical_features, features_to_drop = identify_features(df)\n",
    "    X, y, feature_columns = prepare_data(df, numerical_features, categorical_features, features_to_drop)\n",
    "    preprocessor = create_preprocessing_pipeline(numerical_features, categorical_features)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    model_pipeline = create_model_pipeline(preprocessor)\n",
    "    model_pipeline = train_model(model_pipeline, X_train, y_train)\n",
    "    metrics = evaluate_model(model_pipeline, X_train, X_test, y_train, y_test)\n",
    "    save_model_artifact(model_pipeline, feature_columns)\n",
    "    test_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "5c92c325-604f-4a39-bddc-f98ebf8e04bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOAD AND EXPLORE DATASET\n",
      "============================================================\n",
      "shape of the dataset:\n",
      "(9997, 14)\n",
      "\n",
      "Check for missing values:\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "EstimatedSalary    0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "Exited             0\n",
      "ServiceRating      0\n",
      "dtype: int64\n",
      "\n",
      "First five rows:\n",
      "   CustomerId   Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0    15634602  Hargrave          619    France  Female  42.0       2   \n",
      "1    15647311      Hill          608     Spain  Female  41.0       1   \n",
      "2    15619304      Onio          502    France  Female  42.0       8   \n",
      "3    15701354      Boni          699    France  Female  39.0       1   \n",
      "4    15737888  Mitchell          850     Spain  Female  43.0       2   \n",
      "\n",
      "   EstimatedSalary    Balance  NumOfProducts HasCrCard IsActiveMember  Exited  \\\n",
      "0        101348.88       0.00              1       Yes            Yes       1   \n",
      "1        112542.58   83807.86              1       Yes            Yes       0   \n",
      "2        113931.57  159660.80              3        No             No       1   \n",
      "3         93826.63       0.00              2        No             No       0   \n",
      "4         79084.10  125510.82              1       Yes            Yes       0   \n",
      "\n",
      "   ServiceRating  \n",
      "0              4  \n",
      "1              5  \n",
      "2              3  \n",
      "3              5  \n",
      "4              5  \n",
      "\n",
      "Descriptive Stats:\n",
      "         CustomerId  CreditScore          Age       Tenure  EstimatedSalary  \\\n",
      "count  9.997000e+03  9997.000000  9997.000000  9997.000000      9997.000000   \n",
      "mean   1.569094e+07   650.545364    38.922077     5.013204    100092.222656   \n",
      "std    7.193443e+04    96.657932    10.489072     2.892364     57518.775702   \n",
      "min    1.556570e+07   350.000000    18.000000     0.000000        11.580000   \n",
      "25%    1.562853e+07   584.000000    32.000000     3.000000     50974.570000   \n",
      "50%    1.569073e+07   652.000000    37.000000     5.000000    100236.020000   \n",
      "75%    1.575323e+07   718.000000    44.000000     7.000000    149399.700000   \n",
      "max    1.581569e+07   850.000000    92.000000    10.000000    199992.480000   \n",
      "\n",
      "             Balance  NumOfProducts       Exited  ServiceRating  \n",
      "count    9997.000000    9997.000000  9997.000000    9997.000000  \n",
      "mean    76482.679807       1.530359     0.203761       2.990297  \n",
      "std     62397.174721       0.581669     0.402814       1.423382  \n",
      "min         0.000000       1.000000     0.000000       1.000000  \n",
      "25%         0.000000       1.000000     0.000000       2.000000  \n",
      "50%     97188.620000       1.000000     0.000000       3.000000  \n",
      "75%    127642.440000       2.000000     0.000000       4.000000  \n",
      "max    250898.090000       4.000000     1.000000       5.000000  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9997 entries, 0 to 9996\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CustomerId       9997 non-null   int64  \n",
      " 1   Surname          9997 non-null   object \n",
      " 2   CreditScore      9997 non-null   int64  \n",
      " 3   Geography        9997 non-null   object \n",
      " 4   Gender           9997 non-null   object \n",
      " 5   Age              9997 non-null   float64\n",
      " 6   Tenure           9997 non-null   int64  \n",
      " 7   EstimatedSalary  9997 non-null   float64\n",
      " 8   Balance          9997 non-null   float64\n",
      " 9   NumOfProducts    9997 non-null   int64  \n",
      " 10  HasCrCard        9997 non-null   object \n",
      " 11  IsActiveMember   9997 non-null   object \n",
      " 12  Exited           9997 non-null   int64  \n",
      " 13  ServiceRating    9997 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(5)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "\\Exited Distribution:\n",
      "Exited\n",
      "0    7960\n",
      "1    2037\n",
      "Name: count, dtype: int64\n",
      "\\Exited Percentage Distribution:\n",
      "Exited\n",
      "0    79.623887\n",
      "1    20.376113\n",
      "Name: proportion, dtype: float64\n",
      "============================================================\n",
      "IDETIFYING  OF FEATURES \n",
      "============================================================\n",
      "\n",
      "Featueres to drop ['CustomerId', 'Surname']\n",
      "\n",
      "Numerical Features ['CreditScore', 'Age', 'Tenure', 'EstimatedSalary', 'Balance', 'NumOfProducts', 'ServiceRating']\n",
      "\n",
      "Categorical Features ['Geography', 'Gender', 'HasCrCard']\n",
      "============================================================\n",
      "PREPARE  DATASET \n",
      "============================================================\n",
      "\n",
      "Features Shape (9997, 11)\n",
      "\n",
      "Target Shape (9997,)\n",
      "\n",
      "Feature columns list ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'EstimatedSalary', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'ServiceRating']\n",
      "============================================================\n",
      "CREATING PREPROCESSING  PIPELINE \n",
      "============================================================\n",
      "============================================================\n",
      "SPLITTING DATA INTO TRAIN/TEST\n",
      "============================================================\n",
      "\n",
      "Train set size 7997\n",
      "\n",
      "Test set size 2000\n",
      "\n",
      "Train churn Distribution Exited\n",
      "0    6368\n",
      "1    1629\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Churn Distribution Exited\n",
      "0    1592\n",
      "1     408\n",
      "Name: count, dtype: int64\n",
      "============================================================\n",
      "CREATING MODEL PIPELINE\n",
      "============================================================\n",
      "\n",
      "Model pipeline created succesfully\n",
      "============================================================\n",
      "TRAIN MODEL\n",
      "============================================================\n",
      "\n",
      "Model trained successfully\n",
      "\n",
      "Top 10 most importance fatures(by coefficent magnitude)\n",
      "  feature_columns  coefficient\n",
      "    HasCrCard_Yes    -0.875710\n",
      "Geography_Germany     0.832362\n",
      "              Age     0.810875\n",
      "      Gender_Male    -0.571232\n",
      "          Balance     0.178323\n",
      "      CreditScore    -0.070785\n",
      "  Geography_Spain     0.065863\n",
      "  EstimatedSalary     0.046178\n",
      "    NumOfProducts    -0.045786\n",
      "           Tenure    -0.034700\n",
      "============================================================\n",
      "EVALUATING MODEL\n",
      "============================================================\n",
      "\n",
      "METRICS EVALUATION\n",
      "\n",
      "Train accuracy score:, 0.7126\n",
      "\n",
      "Test accuracy score:, 0.7230\n",
      "\n",
      "Train ROC Score:, 0.7691\n",
      "\n",
      "Test ROC Score:, 0.7779\n",
      "\n",
      " CLASSIFICATION OF TRAIN SIZE\n",
      "\n",
      " Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.90      0.72      0.80      6368\n",
      "     Churned       0.39      0.70      0.50      1629\n",
      "\n",
      "    accuracy                           0.71      7997\n",
      "   macro avg       0.64      0.71      0.65      7997\n",
      "weighted avg       0.80      0.71      0.74      7997\n",
      "\n",
      "\n",
      " CLASSIFICATION OF TEST SIZE\n",
      "\n",
      " Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Retained       0.90      0.73      0.81      1592\n",
      "     Churned       0.40      0.69      0.51       408\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.71      0.66      2000\n",
      "weighted avg       0.80      0.72      0.75      2000\n",
      "\n",
      "\n",
      "Cross Validation (5-folds)\n",
      "R2 Score:[0.75668394 0.79645771 0.75180292 0.78230257 0.7497241 ]\n",
      "Cross Validation mean: 0.77\n",
      "Cross Validation STD : 0.0186\n",
      "============================================================\n",
      "SAVING MODEL ARTIFACT\n",
      "============================================================\n",
      "churned model pipeline saved successfully\n",
      "feature columns saved successfully\n",
      "============================================================\n",
      " MODEL ARTIFACT SAVED SUCCESSFULLY\n",
      "============================================================\n",
      "Prediction Retained\n",
      "Churned Probability 0.8542132956239372\n",
      "Retained Probability 0.14578670437606273\n",
      "Risk Level Medium\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1322e-c850-479d-97dd-a38971ba6e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9a43a-5e66-4bb4-b716-b535e4ab9818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
