{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e83429-9d14-4af4-a219-54808ad552ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing of libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b35bb3-3457-4bbc-b8ad-04bba6060d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_dataset(filepath):\n",
    "    print('=' * 60)\n",
    "    print(\"LOAD AND EXPLORE DATASET\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    print('shape of the dataset:')\n",
    "    print(df.shape)\n",
    "    print('\\nCheck for missing values:')\n",
    "    print(df.isnull().sum())\n",
    "    print('\\nFirst five rows:')\n",
    "    print(df.head())\n",
    "    print('\\nDescriptive Stats:')\n",
    "    print(df.describe())\n",
    "    print('\\nDataset info:')\n",
    "    print(df.info())\n",
    "    print('\\nConditon Distribution:')\n",
    "    print(df['condition'].value_counts())\n",
    "    print('\\nTransmission Distribution:')\n",
    "    print(df['transmission'].value_counts())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294e0c1-64d6-4f9f-bc4b-b7b0b4b0af2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09022a-fc4a-48d7-8ce9-ac3103649f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(df):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('PREPROCESSING LOAD DATA')\n",
    "    print('=' * 60)\n",
    "\n",
    "    df_processed = df.copy()\n",
    "    df_processed = df.dropna()\n",
    "\n",
    "    label_encoder = {}\n",
    "    df_columns = ['make', 'model', 'condition', 'transmission']\n",
    "    for col in df_columns:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col + '_encoded'] = le.fit_transform(df_processed[col])\n",
    "        label_encoder[col] = le\n",
    "        print(f'\\n{col} encoded')\n",
    "        for i, label in enumerate(le.classes_):\n",
    "            print(f\" {label}: {i}\")\n",
    "    print(\"preprocessed_dataset shape\", df_processed.shape)\n",
    "\n",
    "    return df_processed, label_encoder     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb797e-3d8b-4cfb-bda6-ded5bcaa3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_data(df_processed):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('FEATURES DATA')\n",
    "    print('=' * 60)\n",
    "\n",
    "    feature_cols = ['year', 'make_encoded', 'model_encoded', 'condition_encoded', 'transmission_encoded']\n",
    "    target_col = ['price']\n",
    "\n",
    "    X = df_processed[feature_cols]\n",
    "    y = df_processed[target_col]\n",
    "    \n",
    "    print('\\nFeatures shape', df_processed[feature_cols].shape)\n",
    "    print('\\nTarget shape', df_processed[target_col].shape)\n",
    "\n",
    "    \n",
    "    return X, y, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32339720-4e85-4242-a279-c873dae3f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('SPLITING  DATA')\n",
    "    print('=' * 60)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size= test_size, random_state = random_state\n",
    "    )\n",
    "\n",
    "    print('\\n Training set size', X_train.shape[0])\n",
    "    print('Testing set size', X_test.shape[0])\n",
    "    print(\"\\nTraining set price range ₦{:.2f} - ₦{:.2f}\".format(\n",
    "       float( y_train.min()), float(y_train.max())\n",
    "    ))\n",
    "    print(\"\\nTesting set price range₦{:.2f} - ₦{:.2f}\".format(\n",
    "        float(y_test.min()), float(y_test.max())\n",
    "    ))\n",
    "\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935434c0-c6bd-4a4b-9e05-ff7cd774a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X_train, X_test):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('SCALE FEATURES  DATA')\n",
    "    print('=' * 60)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print('\\nFeatures scaled successfully')\n",
    "    print('Trainnig scaled set:', X_train_scaled.shape)\n",
    "    print('Testing scaled set:', X_test_scaled.shape)\n",
    "\n",
    "    return  X_train_scaled, X_test_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e9ac4-9fa1-4f89-91fc-a461fa950ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train_scaled, y_train, feature_cols):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TRAINING MODEL')\n",
    "    print('=' * 60)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print('\\nModel trained successfully')\n",
    "    print('\\nModel coefficient')\n",
    "    for features, coef in zip(feature_cols, model.coef_.ravel()):\n",
    "        print(f\" {features} : {coef:.2f}\")\n",
    "    print(f'\\nModel intercept:{float(model.intercept_):.2f}')\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b7f323-e8e0-401d-a435-4e98f74b0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_model(X_train_scaled, y_train, feature_cols):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TRAINING RANDOM FOREST MODEL')\n",
    "    print('=' * 60)\n",
    "\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf = 2,\n",
    "        random_state = 42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_model.fit(X_train_scaled, y_train)\n",
    "    print('Random forest successfully trained')\n",
    "    print('Model estimators', rf_model.estimator)\n",
    "    print('Model max depth', rf_model.max_depth)\n",
    "    feature_importance = sorted(zip(feature_cols, rf_model.feature_importances_),\n",
    "                                key = lambda x: x[1], reverse=True)\n",
    "    for feature, importance in feature_importance:\n",
    "        print(f\"  {feature}: {float(importance):.4f}\")\n",
    "    return rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdba56-22fe-4d73-9399-ed82c4f30285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('EVALUATING  DATA')\n",
    "    print('=' * 60)\n",
    "\n",
    "    # make prediction\n",
    "\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # calculate metrics\n",
    "    train_r2 = r2_score(y_train_pred, y_train)\n",
    "    test_r2 = r2_score(y_test_pred, y_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_pred, y_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_pred, y_test))\n",
    "    train_mae = mean_absolute_error(y_train_pred, y_train)\n",
    "    test_mae = mean_absolute_error(y_test_pred, y_test)\n",
    "    \n",
    "    print('\\n' + '=' * 60)\n",
    "    print('MODEL  PERFORMANCE')\n",
    "    print('=' * 60)\n",
    "    print('\\nTraining set')\n",
    "    print(f'R2 score: {train_r2:.4f}')\n",
    "    print(f'RMSE: {train_rmse:2.2f}')\n",
    "    print(f'MAE: {train_mae:2.2f}')\n",
    "    print('\\nTestin set')\n",
    "    print(f'R2 score: {test_r2:.4f}')\n",
    "    print(f'RMSE: {test_rmse:2.2f}')\n",
    "    print(f'MAE: {test_mae:2.2f}')\n",
    "    print('=' * 60)\n",
    "\n",
    "    # cross validation score\n",
    "    cv_score = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    print('\\nCross Validation (5-folds)')\n",
    "    print(f'R2 Score:{cv_score}')\n",
    "    print(f'Cross Validation mean: {cv_score.mean():.2f}')\n",
    "    print(f\"Cross Validation STD : {cv_score.std():.4f}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"train_r2\":train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"train_mae\": train_mae,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"y_train_pred\": y_train_pred,\n",
    "        'y_test_pred':y_test_pred,\n",
    "        \"cv_score\":cv_score\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16df415-b2f4-413d-9399-ddf429eb3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rf_model(rf_model, X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('EVALUATING  DATA')\n",
    "    print('=' * 60)\n",
    "\n",
    "    # make prediction\n",
    "\n",
    "    y_train_pred = rf_model.predict(X_train_scaled)\n",
    "    y_test_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "    # calculate metrics\n",
    "    train_r2 = r2_score(y_train_pred, y_train)\n",
    "    test_r2 = r2_score(y_test_pred, y_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_pred, y_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test_pred, y_test))\n",
    "    train_mae = mean_absolute_error(y_train_pred, y_train)\n",
    "    test_mae = mean_absolute_error(y_test_pred, y_test)\n",
    "    \n",
    "    print('\\n' + '=' * 60)\n",
    "    print('RANDOM FORESRT MODEL  PERFORMANCE')\n",
    "    print('=' * 60)\n",
    "    print('\\nTraining set')\n",
    "    print(f'R2 score: {train_r2:.4f}')\n",
    "    print(f'RMSE: {train_rmse:2.2f}')\n",
    "    print(f'MAE: {train_mae:2.2f}')\n",
    "    print('\\nTestin set')\n",
    "    print(f'R2 score: {test_r2:.4f}')\n",
    "    print(f'RMSE: {test_rmse:2.2f}')\n",
    "    print(f'MAE: {test_mae:2.2f}')\n",
    "    print('=' * 60)\n",
    "\n",
    "    # cross validation score\n",
    "    cv_score = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    print('\\nCross Validation (5-folds)')\n",
    "    print(f'R2 Score:{cv_score}')\n",
    "    print(f'Cross Validation mean: {cv_score.mean():.2f}')\n",
    "    print(f\"Cross Validation STD : {cv_score.std():.4f}\")\n",
    "\n",
    "    rf_metrics = {\n",
    "        \"train_r2\":train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"train_mae\": train_mae,\n",
    "        \"test_mae\": test_mae,\n",
    "        \"y_train_pred\": y_train_pred,\n",
    "        'y_test_pred':y_test_pred,\n",
    "        \"cv_score\":cv_score\n",
    "    }\n",
    "\n",
    "    return rf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5d7d9-a325-42aa-a637-fa840d224431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving of activities\n",
    "def save_model_artifact(model, scaler, label_encoders, feature_cols):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('SAVING MODEL ARTIFACT')\n",
    "    print('=' * 60)\n",
    "    joblib.dump(model, 'car_price_prediction.pkl')\n",
    "    print('Car price prediction model saved successfully')\n",
    "    \n",
    "    joblib.dump(scaler, 'scaler_features.pkl')\n",
    "    print('Scaler prediction saved successfully')\n",
    "    \n",
    "    joblib.dump(label_encoders, 'label_encoders.pkl')\n",
    "    print('label encoder saved successfully')\n",
    "    \n",
    "    joblib.dump(feature_cols, 'feature_columns.pkl')\n",
    "    print('Feature columns saved successfully')\n",
    "\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('All  MODEL ARTIFACT SAVED SUCCESSFULLY')\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056296d1-9dc9-4fa6-a281-e2ba8144fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving of activities\n",
    "def save_rf_model_artifact(rf_model):\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('SAVING RANDOM FOREST MODEL ARTIFACT')\n",
    "    print('=' * 60)\n",
    "    joblib.dump(rf_model, 'rf_model_prediction.pkl')\n",
    "    print('Car price prediction model saved successfully')\n",
    "\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('RANDOM FOREST MODEL ARTIFACT SAVED SUCCESSFULLY')\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c024208-1698-455b-bca7-628cc054b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_car_price(year,  make, model_name, condition, transmission):\n",
    "    model = joblib.load('car_price_prediction.pkl')\n",
    "    scaler = joblib.load('scaler_features.pkl')\n",
    "    label_encoders = joblib.load('label_encoders.pkl')\n",
    "    feature_cols = joblib.load('feature_columns.pkl')\n",
    "    try:\n",
    "        make_encoded = label_encoders['make'].transform([make])[0]\n",
    "        model_encoded = label_encoders['model'].transform([model_name])[0]\n",
    "        condition_encoded = label_encoders['condition'].transform([condition])[0]\n",
    "        transmission_encoded = label_encoders['transmission'].transform([transmission])[0]\n",
    "    except ValueError as e:\n",
    "        return f\"Unknown category - {e}\"\n",
    "    features_dict = {\n",
    "        'year': year,\n",
    "        'make_encoded': make_encoded,\n",
    "        'model_encoded': model_encoded,\n",
    "        'condition_encoded': condition_encoded,\n",
    "        'transmission_encoded': transmission_encoded\n",
    "    }\n",
    "    features = np.array([[features_dict[col] for col in features_dict]])\n",
    "    features_scale = scaler.transform(features)\n",
    "    predict_price = model.predict(features_scale)[0]\n",
    "    return predict_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b198a-775f-4595-b866-9fa881ca56c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model_predict_car_price(year,  make, model_name, condition, transmission):\n",
    "    rf_model = joblib.load('rf_model_prediction.pkl')\n",
    "    scaler = joblib.load('scaler_features.pkl')\n",
    "    label_encoders = joblib.load('label_encoders.pkl')\n",
    "    feature_cols = joblib.load('feature_columns.pkl')\n",
    "    try:\n",
    "        make_encoded = label_encoders['make'].transform([make])[0]\n",
    "        model_encoded = label_encoders['model'].transform([model_name])[0]\n",
    "        condition_encoded = label_encoders['condition'].transform([condition])[0]\n",
    "        transmission_encoded = label_encoders['transmission'].transform([transmission])[0]\n",
    "    except ValueError as e:\n",
    "        return f\"Unknown category - {e}\"\n",
    "    features_dict = {\n",
    "        'year': year,\n",
    "        'make_encoded': make_encoded,\n",
    "        'model_encoded': model_encoded,\n",
    "        'condition_encoded': condition_encoded,\n",
    "        'transmission_encoded': transmission_encoded\n",
    "    }\n",
    "    features = np.array([[features_dict[col] for col in features_dict]])\n",
    "    features_scale = scaler.transform(features)\n",
    "    predict_price = rf_model.predict(features_scale)[0]\n",
    "    return predict_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb932cb-1e9b-4aac-897e-2517fba489d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction():\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TESTING  PREDICTION')\n",
    "    print('=' * 60)\n",
    "\n",
    "    # example no.1\n",
    "    price1 = predict_car_price(2015,'Toyota', 'Camry', 'Local used', 'Automatic')\n",
    "    print('\\n 2015 Toyota Camry (foreign used Automatic)')\n",
    "    print(f\" ₦{float(price1):,.2f}\")\n",
    "\n",
    "    # example no.2\n",
    "    price2 = predict_car_price(2010,'Honda', 'Accord', 'Local used', 'Automatic')\n",
    "    print('\\n 2010 Honda Accord (Local used Automatic)')\n",
    "    print(f\" ₦{float(price2):,.2f}\")\n",
    "\n",
    "    # example no.1\n",
    "    price3 = predict_car_price(2012,'Lexus', 'RX 350', 'Foreign used', 'Automatic')\n",
    "    print('\\n 2012 Lexus RX 350 (foreign used Automatic)')\n",
    "    print(f\" ₦{float(price3):,.2f}\")\n",
    "    \n",
    "    print('=' * 60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0859e2-ecb4-404f-9ce8-c1589fd817cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rf_model_prediction():\n",
    "    print('\\n' + '=' * 60)\n",
    "    print('TESTING  PREDICTION')\n",
    "    print('=' * 60)\n",
    "\n",
    "    # example no.1\n",
    "    price1 = rf_model_predict_car_price(2015,'Toyota', 'Camry', 'Local used', 'Automatic')\n",
    "    print('\\n 2015 Toyota Camry (foreign used Automatic)')\n",
    "    print(f\" ₦{float(price1):,.2f}\")\n",
    "\n",
    "    # example no.2\n",
    "    price2 = rf_model_predict_car_price(2010,'Honda', 'Accord', 'Local used', 'Automatic')\n",
    "    print('\\n 2010 Honda Accord (Local used Automatic)')\n",
    "    print(f\" ₦{float(price2):,.2f}\")\n",
    "\n",
    "    # example no.1\n",
    "    price3 = rf_model_predict_car_price(2012,'Lexus', 'RX 350', 'Foreign used', 'Automatic')\n",
    "    print('\\n 2012 Lexus RX 350 (foreign used Automatic)')\n",
    "    print(f\" ₦{float(price3):,.2f}\")\n",
    "    \n",
    "    print('=' * 60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da6574e-1fb2-4dd1-8994-5cf7495d787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    filepath = 'cleaned_jiji_car_dataset.csv'\n",
    "    \n",
    "    df = load_and_explore_dataset(filepath)\n",
    "    \n",
    "    df_processed, label_encoders = preprocessing_data(df)\n",
    "    \n",
    "    X, y, feature_cols = features_data(df_processed)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    \n",
    "    X_train_scaled, X_test_scaled, scaler = scale_features(X_train, X_test)\n",
    "    \n",
    "    model = train_model(X_train_scaled, y_train, feature_cols)\n",
    "    \n",
    "    \n",
    "    metrics = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \n",
    "   \n",
    "    \n",
    "    save_model_artifact(model, scaler, label_encoders, feature_cols)\n",
    "    \n",
    "    test_prediction()\n",
    "    \n",
    "    rf_model = train_random_forest_model(X_train_scaled, y_train, feature_cols)\n",
    "    \n",
    "    rf_metrics = evaluate_rf_model(rf_model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    save_rf_model_artifact(rf_model)\n",
    "    test_rf_model_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1cae2-87ed-4987-ba4c-086aee4537bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aef6be-7eff-45d1-8138-96682f55eb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d579db3-55c5-4b1f-beb7-3b5edc653215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525f059-d6f1-42fe-a7a5-7b8a69988e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f426c0d-6bf5-4be7-bd0f-b61f10821da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef159fad-2000-4407-a2cd-02f4c146bcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
