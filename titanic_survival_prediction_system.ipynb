{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71835224-0aa2-440a-b2e6-16cf34bf6e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# improting of libaries\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da81f41-6105-4d96-8420-494a5ea574eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_explore_dataset(filepath):\n",
    "    print('=' * 60)\n",
    "    print(\"LOAD AND EXPLORE DATASET\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    print('shape of the dataset:')\n",
    "    print(df.shape)\n",
    "    print('\\nCheck for missing values:')\n",
    "    print(df.isnull().sum())\n",
    "    print('\\nFirst five rows:')\n",
    "    print(df.head())\n",
    "    print('\\nDescriptive Stats:')\n",
    "    print(df.describe())\n",
    "    print('\\nDataset info:')\n",
    "    print(df.info())\n",
    "    print('\\Survived Distribution:')\n",
    "    print(df['Survived'].value_counts())\n",
    "    print('\\Survived Percentage Distribution:')\n",
    "    print(df['Survived'].value_counts(normalize=True)* 100)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc49253-c26f-45bb-a886-483272117915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_features(df):\n",
    "    print('=' * 60)\n",
    "    print(\"IDETIFYING  OF FEATURES \")\n",
    "    print('=' * 60)\n",
    "    # features to be drop(not useful)\n",
    "    features_to_drop = [\n",
    "        \"PassengerId\",\n",
    "        'SibSp',\n",
    "        'Parch'\n",
    "    ]\n",
    "\n",
    "    numerical_features = [\n",
    "    'Pclass', 'Age',\n",
    "    'Fare','Embarked'   \n",
    "    ]\n",
    "\n",
    "    categorical_features = [\n",
    "         \"Sex\"\n",
    "    ] \n",
    "    print('\\nFeatueres to drop', features_to_drop)\n",
    "    print('\\nNumerical Features', numerical_features)\n",
    "    print('\\nCategorical Features', categorical_features)\n",
    "    return numerical_features, categorical_features, features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7213f42c-f52a-44b5-a372-441d6c9f13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, numerical_features, categorical_features, features_to_drop):\n",
    "    print('=' * 60)\n",
    "    print(\"PREPARE  DATASET \")\n",
    "    print('=' * 60)\n",
    "\n",
    "    # drop unnecessary cols\n",
    "    df_model = df.drop(columns=features_to_drop)\n",
    "\n",
    "    # featyre to use\n",
    "    X = df_model.drop('Survived', axis= 1)\n",
    "    y = df_model['Survived']\n",
    "\n",
    "    print(\"\\nFeatures Shape\", X.shape)\n",
    "    print(\"\\nTarget Shape\", y.shape)\n",
    "    print(\"\\nFeature columns list\", list(X.columns))\n",
    "\n",
    "    return X, y, list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7945c1e6-506a-4ba3-b435-da69f940cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessing_pipeline(numerical_features, categorical_features):\n",
    "    print('=' * 60)\n",
    "    print(\"CREATING PREPROCESSING  PIPELINE \")\n",
    "    print('=' * 60)\n",
    "\n",
    "    # nmerical_features pipeline\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # categorical features pipeline\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown = 'ignore'))\n",
    "    ])\n",
    "    #  column preprocessing\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4757b46-8172-4943-b1e9-134f571d9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    print('=' * 60)\n",
    "    print(\"SPLITTING DATA INTO TRAIN/TEST\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,y, test_size= test_size, random_state = random_state, stratify=y\n",
    "    )\n",
    "    print('\\nTrain set size', X_train.shape[0])\n",
    "    print('\\nTest set size', X_test.shape[0])\n",
    "    print('\\nTrain Survival Distribution', y_train.value_counts())\n",
    "    print('\\nTest Survival Distribution', y_test.value_counts())\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee98171-2faf-47a3-98f2-2bcd241da97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_pipeline(preprocessor):\n",
    "    print('=' * 60)\n",
    "    print(\"CREATING MODEL PIPELINE\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(\n",
    "            max_iter =100,\n",
    "            random_state = 42,\n",
    "            class_weight= 'balanced',\n",
    "            solver= 'lbfgs'\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print('\\nModel pipeline created succesfully')\n",
    "\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c884c3c8-7e99-4ba9-a052-d36aefea9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_pipeline, X_train, y_train):\n",
    "    print('=' * 60)\n",
    "    print(\"TRAIN MODEL\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    print('\\nModel trained successfully')\n",
    "\n",
    "    # get name steps from preprocessing\n",
    "    try:\n",
    "        num_features = model_pipeline.named_steps['preprocessor'].transformers_[0][2]\n",
    "        cat_features = model_pipeline.named_steps['preprocessor'].transformers_[1][2]\n",
    "\n",
    "        # get name_Steps from onehotencoder\n",
    "        onehot_encoder = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n",
    "        cat_features_name = onehot_encoder.get_feature_names_out(cat_features)\n",
    "\n",
    "        all_features_name = list(num_features) + list(cat_features_name)\n",
    "\n",
    "        # get coefficient \n",
    "        coefficient = model_pipeline.named_steps['classifier'].coef_[0]\n",
    "        print('\\nTop 5 most importance fatures(by coefficent magnitude)')\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature_columns': all_features_name,\n",
    "            'coefficient': coefficient\n",
    "        }).sort_values('coefficient', key=abs, ascending=False)\n",
    "        print(feature_importance.head(10).to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Can not extract features name {e}\")\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e720bf3f-e9bb-4799-96d0-4ce533359a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_pipeline, X_train, X_test, y_train, y_test):\n",
    "    print('=' * 60)\n",
    "    print(\"EVALUATING MODEL\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    y_train_pred = model_pipeline.predict(X_train)\n",
    "    y_test_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "    # predict model prob\n",
    "    y_train_proba = model_pipeline.predict_proba(X_train)[:,1]\n",
    "    y_test_proba = model_pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # metrics \n",
    "    y_train_acc_score = accuracy_score(y_train, y_train_pred)\n",
    "    y_test_acc_Score = accuracy_score(y_test_pred, y_test)\n",
    "\n",
    "    y_train_roc_score = roc_auc_score(y_train, y_train_proba)\n",
    "    y_test_roc_score = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "    print(\"\\nMETRICS EVALUATION\")\n",
    "    print(f\"\\nTrain accuracy score:, {float(y_train_acc_score):.4f}\")\n",
    "    print(f\"\\nTest accuracy score:, {float(y_test_acc_Score):.4f}\")\n",
    "    print(f\"\\nTrain ROC Score:, {float(y_train_roc_score):.4f}\")\n",
    "    print(f\"\\nTest ROC Score:, {float(y_test_roc_score):.4f}\")\n",
    "\n",
    "    print(\"\\n CLASSIFICATION OF TRAIN SIZE\")\n",
    "    print(\"\\n Classification report\\n\", classification_report(y_train, y_train_pred, target_names = ['No','Yes']))\n",
    "    print(\"\\n CLASSIFICATION OF TEST SIZE\")\n",
    "    print(\"\\n Classification report\\n\", classification_report(y_test, y_test_pred, target_names = ['No','Yes']))\n",
    "\n",
    "    # cross validation score\n",
    "    cv_score = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "    print('\\nCross Validation (5-folds)')\n",
    "    print(f'R2 Score:{cv_score}')\n",
    "    print(f'Cross Validation mean: {cv_score.mean():.2f}')\n",
    "    print(f\"Cross Validation STD : {cv_score.std():.4f}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"y_train_acc_score\": y_train_acc_score,\n",
    "        \"y_test_acc_Score\": y_test_acc_Score,\n",
    "        \"y_train_roc_score\": y_train_roc_score,\n",
    "        \"y_test_roc_score\": y_test_roc_score, \n",
    "        \"y_train_pred\": y_train_pred,\n",
    "        \"y_test_pred\": y_test_pred,\n",
    "        'y_train_proba':y_train_proba,\n",
    "        \"y_test_proba\": y_test_proba,\n",
    "        \"cv_score\":cv_score,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a8a5b2-5194-44c8-b55c-d3355067865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_artifact(model_pipeline, feature_columns):\n",
    "    print('=' * 60)\n",
    "    print(\"SAVING MODEL ARTIFACT\")\n",
    "    print('=' * 60)\n",
    "\n",
    "    joblib.dump(model_pipeline, 'survival_model_pipeline.pkl')\n",
    "    print('Survival model pipeline saved successfully')\n",
    "    \n",
    "    joblib.dump(feature_columns, 'survival_feature_columns.pkl')\n",
    "    print('feature columns saved successfully')\n",
    "\n",
    "    print('=' * 60)\n",
    "    print(\" MODEL ARTIFACT SAVED SUCCESSFULLY\")\n",
    "    print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700ae26d-289e-458c-8366-00fbcc1fef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_survival (customer_data):\n",
    "    model_pipeline = joblib.load(\"survival_model_pipeline.pkl\")\n",
    "    feature_columns = joblib.load(\"feature_columns.pkl\")\n",
    "    customer_df = pd.DataFrame([customer_data])\n",
    "    for feature in feature_columns:\n",
    "        if feature not in customer_df.columns:\n",
    "            raise ValueError(f\"Missing require feature{feature}\")\n",
    "    customer_df = customer_df[feature_columns]\n",
    "    \n",
    "    prediction = model_pipeline.predict(customer_df)[0]\n",
    "    probability = model_pipeline.predict_proba(customer_df)[0]\n",
    "\n",
    "    result = {\n",
    "    'prediction': 'Yes' if prediction == 1 else \"No\",\n",
    "    'unsurvive_probability': probability[0],\n",
    "    'survive_probability': probability[1],\n",
    "    'survival_rate': 'High' if probability [1] > 0.6 else 'Medium' if probability[1] > 0.3 else 'Low'\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b9f4c50-9ff3-4a93-900e-eae2cbb3a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    customer_data = {\n",
    "    'Pclass': 1,\n",
    "    'Sex': 'Male',\n",
    "    'Age': 23,\n",
    "    'Fare': 87.554,\n",
    "    'Embarked': 1\n",
    "    }\n",
    "    result = predict_survival (customer_data)\n",
    "    print(\"Survived:\", result['prediction'])\n",
    "    print(\"Unsurvive Probability:\", result['unsurvive_probability'])\n",
    "    print(\"Survive Probability:\", result['survive_probability'])\n",
    "    print(\"Survival rate:\", result['survival_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9347bfb5-24cc-4a02-9a7c-b60e7b5b2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    filepath  = 'SVMtrain.csv'\n",
    "    df = load_and_explore_dataset(filepath)\n",
    "    numerical_features, categorical_features, features_to_drop = identify_features(df)\n",
    "    X, y, feature_columns = prepare_data(df, numerical_features, categorical_features, features_to_drop)\n",
    "    preprocessor = create_preprocessing_pipeline(numerical_features, categorical_features)\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "    model_pipeline = create_model_pipeline(preprocessor)\n",
    "    model_pipeline = train_model(model_pipeline, X_train, y_train)\n",
    "    metrics = evaluate_model(model_pipeline, X_train, X_test, y_train, y_test)\n",
    "    save_model_artifact(model_pipeline, feature_columns)\n",
    "    test_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa563b3-e2a0-4a43-84f1-5ddb7953d861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOAD AND EXPLORE DATASET\n",
      "============================================================\n",
      "shape of the dataset:\n",
      "(889, 9)\n",
      "\n",
      "Check for missing values:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "\n",
      "First five rows:\n",
      "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare  \\\n",
      "0            1         0       3    Male  22.0      1      0   7.2500   \n",
      "1            2         1       1  female  38.0      1      0  71.2833   \n",
      "2            3         1       3  female  26.0      0      0   7.9250   \n",
      "3            4         1       1  female  35.0      1      0  53.1000   \n",
      "4            5         0       3    Male  35.0      0      0   8.0500   \n",
      "\n",
      "   Embarked  \n",
      "0         3  \n",
      "1         1  \n",
      "2         3  \n",
      "3         3  \n",
      "4         3  \n",
      "\n",
      "Descriptive Stats:\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   889.000000  889.000000  889.000000  889.000000  889.000000   \n",
      "mean    446.000000    0.382452    2.311586   35.686355    0.524184   \n",
      "std     256.998173    0.486260    0.834700   17.756733    1.103705   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     224.000000    0.000000    2.000000   22.000000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   32.000000    0.000000   \n",
      "75%     668.000000    1.000000    3.000000   54.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare    Embarked  \n",
      "count  889.000000  889.000000  889.000000  \n",
      "mean     0.382452   32.096681    2.535433  \n",
      "std      0.806761   49.697504    0.792088  \n",
      "min      0.000000    0.000000    1.000000  \n",
      "25%      0.000000    7.895800    2.000000  \n",
      "50%      0.000000   14.454200    3.000000  \n",
      "75%      0.000000   31.000000    3.000000  \n",
      "max      6.000000  512.329200    3.000000  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 889 entries, 0 to 888\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  889 non-null    int64  \n",
      " 1   Survived     889 non-null    int64  \n",
      " 2   Pclass       889 non-null    int64  \n",
      " 3   Sex          889 non-null    object \n",
      " 4   Age          889 non-null    float64\n",
      " 5   SibSp        889 non-null    int64  \n",
      " 6   Parch        889 non-null    int64  \n",
      " 7   Fare         889 non-null    float64\n",
      " 8   Embarked     889 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 62.6+ KB\n",
      "None\n",
      "\\Survived Distribution:\n",
      "Survived\n",
      "0    549\n",
      "1    340\n",
      "Name: count, dtype: int64\n",
      "\\Survived Percentage Distribution:\n",
      "Survived\n",
      "0    61.754781\n",
      "1    38.245219\n",
      "Name: proportion, dtype: float64\n",
      "============================================================\n",
      "IDETIFYING  OF FEATURES \n",
      "============================================================\n",
      "\n",
      "Featueres to drop ['PassengerId', 'SibSp', 'Parch']\n",
      "\n",
      "Numerical Features ['Pclass', 'Age', 'Fare', 'Embarked']\n",
      "\n",
      "Categorical Features ['Sex']\n",
      "============================================================\n",
      "PREPARE  DATASET \n",
      "============================================================\n",
      "\n",
      "Features Shape (889, 5)\n",
      "\n",
      "Target Shape (889,)\n",
      "\n",
      "Feature columns list ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked']\n",
      "============================================================\n",
      "CREATING PREPROCESSING  PIPELINE \n",
      "============================================================\n",
      "============================================================\n",
      "SPLITTING DATA INTO TRAIN/TEST\n",
      "============================================================\n",
      "\n",
      "Train set size 711\n",
      "\n",
      "Test set size 178\n",
      "\n",
      "Train Survival Distribution Survived\n",
      "0    439\n",
      "1    272\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Survival Distribution Survived\n",
      "0    110\n",
      "1     68\n",
      "Name: count, dtype: int64\n",
      "============================================================\n",
      "CREATING MODEL PIPELINE\n",
      "============================================================\n",
      "\n",
      "Model pipeline created succesfully\n",
      "============================================================\n",
      "TRAIN MODEL\n",
      "============================================================\n",
      "\n",
      "Model trained successfully\n",
      "\n",
      "Top 5 most importance fatures(by coefficent magnitude)\n",
      "feature_columns  coefficient\n",
      "     Sex_female     2.446038\n",
      "         Pclass    -0.718826\n",
      "            Age    -0.337886\n",
      "       Embarked    -0.252609\n",
      "           Fare     0.039574\n",
      "============================================================\n",
      "EVALUATING MODEL\n",
      "============================================================\n",
      "\n",
      "METRICS EVALUATION\n",
      "\n",
      "Train accuracy score:, 0.7778\n",
      "\n",
      "Test accuracy score:, 0.7809\n",
      "\n",
      "Train ROC Score:, 0.8470\n",
      "\n",
      "Test ROC Score:, 0.8532\n",
      "\n",
      " CLASSIFICATION OF TRAIN SIZE\n",
      "\n",
      " Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.79      0.81       439\n",
      "         Yes       0.69      0.76      0.72       272\n",
      "\n",
      "    accuracy                           0.78       711\n",
      "   macro avg       0.77      0.77      0.77       711\n",
      "weighted avg       0.78      0.78      0.78       711\n",
      "\n",
      "\n",
      " CLASSIFICATION OF TEST SIZE\n",
      "\n",
      " Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.78      0.82       110\n",
      "         Yes       0.69      0.78      0.73        68\n",
      "\n",
      "    accuracy                           0.78       178\n",
      "   macro avg       0.77      0.78      0.77       178\n",
      "weighted avg       0.79      0.78      0.78       178\n",
      "\n",
      "\n",
      "Cross Validation (5-folds)\n",
      "R2 Score:[0.85547521 0.8261233  0.85300926 0.85195707 0.83838384]\n",
      "Cross Validation mean: 0.84\n",
      "Cross Validation STD : 0.0112\n",
      "============================================================\n",
      "SAVING MODEL ARTIFACT\n",
      "============================================================\n",
      "Survival model pipeline saved successfully\n",
      "feature columns saved successfully\n",
      "============================================================\n",
      " MODEL ARTIFACT SAVED SUCCESSFULLY\n",
      "============================================================\n",
      "Survived: Yes\n",
      "Unsurvive Probability: 0.2860762553107691\n",
      "Survive Probability: 0.7139237446892309\n",
      "Survival rate: High\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\" :\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e4107-e61c-4755-acee-938e7c894273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86efe060-7381-43fb-9eac-2b277deda1e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
